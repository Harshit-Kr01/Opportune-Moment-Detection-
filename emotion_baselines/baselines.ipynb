{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6b0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, average_precision_score, confusion_matrix, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Activation, Dropout, Bidirectional, Multiply, Flatten, Lambda,RepeatVector, Permute \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.signal import resample, butter, filtfilt, welch\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"KMeans is known to have a memory leak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b549bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for sampling rates\n",
    "PHYSIO_SAMPLING_RATE = 1000  # Hz\n",
    "VALENCE_SAMPLING_RATE = 20    # Hz\n",
    "DOWNSAMPLE_FACTOR = PHYSIO_SAMPLING_RATE // VALENCE_SAMPLING_RATE  # 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b20ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    columns = [\"time\", \"ECG\", \"BVP\", \"GSR\", \"Resp\", \"Skin_Temp\", \"EMG_z\", \"EMG_c\", \"EMG_t\"]\n",
    "    \n",
    "    # Read all data first\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", names=columns)\n",
    "    \n",
    "    # Downsample physiological data to match valence-arousal sampling rate\n",
    "    downsampled_df = df.iloc[::DOWNSAMPLE_FACTOR, :].copy()\n",
    "    \n",
    "    # Reset time to new sampling rate\n",
    "    downsampled_df[\"time\"] = np.arange(len(downsampled_df)) / VALENCE_SAMPLING_RATE\n",
    "    \n",
    "    return downsampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad11da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment into 5-second windows with proper alignment\n",
    "def segment_data(physio_df, window_size=5):  # Removed valence_df parameter\n",
    "    # Calculate number of samples per window\n",
    "    samples_per_window = window_size * VALENCE_SAMPLING_RATE\n",
    "    \n",
    "    # Segment physiological data only\n",
    "    segments = []\n",
    "    for i in range(0, len(physio_df), samples_per_window):\n",
    "        segment = physio_df.iloc[i:i+samples_per_window]\n",
    "        if len(segment) == samples_per_window:  # only complete segments\n",
    "            # Calculate time-domain features\n",
    "            features = {\n",
    "                \"time\": segment[\"time\"].mean(),\n",
    "                \"ECG_mean\": segment[\"ECG\"].mean(),\n",
    "                \"ECG_std\": segment[\"ECG\"].std(),\n",
    "                \"ECG_hr\": 60 / (segment[\"ECG\"].diff().abs().mean() + 1e-6),\n",
    "                \"BVP_mean\": segment[\"BVP\"].mean(),\n",
    "                \"BVP_std\": segment[\"BVP\"].std(),\n",
    "                \"GSR_mean\": segment[\"GSR\"].mean(),\n",
    "                \"GSR_std\": segment[\"GSR\"].std(),\n",
    "                \"GSR_slope\": np.polyfit(np.arange(len(segment)), segment[\"GSR\"], 1)[0],\n",
    "                \"Resp_mean\": segment[\"Resp\"].mean(),\n",
    "                \"Resp_std\": segment[\"Resp\"].std(),\n",
    "                \"Resp_rate\": len(np.where(np.diff(np.sign(segment[\"Resp\"] - segment[\"Resp\"].mean())))[0]) / 2,\n",
    "                \"Skin_temp_mean\": segment[\"Skin_Temp\"].mean(),\n",
    "                \"Skin_temp_std\": segment[\"Skin_Temp\"].std(),\n",
    "                \"EMG_mean\": segment[[\"EMG_z\", \"EMG_c\", \"EMG_t\"]].mean().mean(),\n",
    "                \"EMG_std\": segment[[\"EMG_z\", \"EMG_c\", \"EMG_t\"]].std().mean()\n",
    "            }\n",
    "            segments.append(features)\n",
    "    \n",
    "    return pd.DataFrame(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d275de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_physiological_features(segment):\n",
    "    \"\"\"Extract time and frequency domain features from a physiological segment\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Time-domain features\n",
    "    for signal in ['ECG', 'BVP', 'GSR', 'Resp', 'Skin_Temp']:\n",
    "        sig_data = segment[signal].values\n",
    "        features.update({\n",
    "            f\"{signal}_mean\": np.mean(sig_data),\n",
    "            f\"{signal}_std\": np.std(sig_data),\n",
    "            f\"{signal}_max\": np.max(sig_data),\n",
    "            f\"{signal}_min\": np.min(sig_data),\n",
    "            f\"{signal}_range\": np.ptp(sig_data),\n",
    "            f\"{signal}_slope\": np.polyfit(np.arange(len(sig_data)), sig_data, 1)[0],\n",
    "            f\"{signal}_diff_mean\": np.mean(np.diff(sig_data)),\n",
    "            f\"{signal}_diff_std\": np.std(np.diff(sig_data))\n",
    "        })\n",
    "    \n",
    "    # Frequency-domain features (using Welch's method)\n",
    "    for signal in ['ECG', 'BVP', 'GSR']:\n",
    "        sig_data = segment[signal].values\n",
    "        f, Pxx = welch(sig_data, fs=VALENCE_SAMPLING_RATE, nperseg=min(len(sig_data), 256))\n",
    "        features.update({\n",
    "            f\"{signal}_psd_mean\": np.mean(Pxx),\n",
    "            f\"{signal}_psd_std\": np.std(Pxx),\n",
    "            f\"{signal}_psd_max\": np.max(Pxx),\n",
    "            f\"{signal}_psd_max_freq\": f[np.argmax(Pxx)],\n",
    "            f\"{signal}_psd_ratio\": np.sum(Pxx[f > 0.1]) / (np.sum(Pxx) + 1e-6)  # ratio of high freq components\n",
    "        })\n",
    "    \n",
    "    # Combined features\n",
    "    features['HRV'] = np.std(np.diff(np.where(np.diff(segment['ECG']) > 0.5 * np.std(segment['ECG']))[0]))\n",
    "    features['GSR_peaks'] = len(find_peaks(segment['GSR'], height=np.mean(segment['GSR']))[0])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bca5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rulsif_change_scores(X, alpha=0.1, sigma=1.0, lambda_param=1e-3):\n",
    "    n = len(X) - 1\n",
    "    change_scores = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_t, X_t_next = X[i], X[i + 1]\n",
    "        \n",
    "        # Compute Gaussian Kernel Matrix\n",
    "        K_t = rbf_kernel(X_t.reshape(-1, 1), X_t.reshape(-1, 1), gamma=1/(2*sigma**2))\n",
    "        K_t_next = rbf_kernel(X_t_next.reshape(-1, 1), X_t_next.reshape(-1, 1), gamma=1/(2*sigma**2))\n",
    "        \n",
    "        # Compute Weights using Least Squares Importance Fitting (LSIF)\n",
    "        H = alpha * K_t + (1 - alpha) * K_t_next + lambda_param * np.eye(K_t.shape[0])\n",
    "        h = np.mean(K_t, axis=1)\n",
    "        \n",
    "        theta = np.linalg.solve(H, h)\n",
    "        \n",
    "        # Compute Change Score\n",
    "        change_scores[i] = np.mean(np.square(K_t_next.dot(theta) - 1))\n",
    "    \n",
    "    return change_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9889f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_opportune_moments(change_scores):\n",
    "    mean, std = np.mean(change_scores), np.std(change_scores)\n",
    "    threshold = mean + 3 * std\n",
    "    outliers = change_scores > threshold\n",
    "    \n",
    "    # Clustering the remaining scores\n",
    "    valid_indices = np.where(~outliers)[0]  # Indices of non-outliers\n",
    "    valid_scores = change_scores[valid_indices]\n",
    "    \n",
    "    if len(valid_scores) > 1:  # Ensure there are enough samples for clustering\n",
    "        kmeans = KMeans(n_clusters=2, random_state=42).fit(valid_scores.reshape(-1, 1))\n",
    "        centroids = kmeans.cluster_centers_.flatten()\n",
    "        high_cluster = np.argmax(centroids)\n",
    "        high_values = (kmeans.labels_ == high_cluster) & (valid_scores > centroids[high_cluster])\n",
    "        \n",
    "        # Map high_values back to the original indices\n",
    "        high_values_mapped = np.zeros_like(change_scores, dtype=bool)\n",
    "        high_values_mapped[valid_indices] = high_values\n",
    "    else:\n",
    "        high_values_mapped = np.zeros_like(change_scores, dtype=bool)\n",
    "    \n",
    "    # Mark opportune moments\n",
    "    opportune_moments = np.where(outliers | high_values_mapped)[0]\n",
    "    return opportune_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca079e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(segmented_data, change_scores):\n",
    "    # Select only physiological features\n",
    "    features = [\n",
    "        'ECG_mean', 'ECG_std', 'ECG_hr', \n",
    "        'BVP_mean', 'BVP_std',\n",
    "        'GSR_mean', 'GSR_std', 'GSR_slope',\n",
    "        'Resp_mean', 'Resp_std', 'Resp_rate',\n",
    "        'Skin_temp_mean', 'Skin_temp_std',\n",
    "        'EMG_mean', 'EMG_std'\n",
    "    ]\n",
    "    \n",
    "    # Add change point scores\n",
    "    segmented_data['change_score'] = np.concatenate([[0], change_scores])[:len(segmented_data)]\n",
    "    \n",
    "    # Prepare input sequence\n",
    "    input_sequence = segmented_data[features + ['change_score']].values\n",
    "    \n",
    "    # Robust scaling\n",
    "    scaler = RobustScaler()\n",
    "    input_sequence = scaler.fit_transform(input_sequence)\n",
    "    \n",
    "    return input_sequence\n",
    "\n",
    "def prepare_input_student(segmented_data, change_scores):\n",
    "    # Features only from BVP, GSR, and Skin Temperature + change scores\n",
    "    features = [\n",
    "        'BVP_mean', 'BVP_std',\n",
    "        'GSR_mean', 'GSR_std', 'GSR_slope',\n",
    "        'Skin_temp_mean', 'Skin_temp_std'\n",
    "    ]\n",
    "    \n",
    "    # Add change point scores (same as before)\n",
    "    segmented_data['change_score'] = np.concatenate([[0], change_scores])[:len(segmented_data)]\n",
    "    \n",
    "    # Prepare input sequence with selected features\n",
    "    input_sequence = segmented_data[features + ['change_score']].values\n",
    "    \n",
    "    # Apply robust scaling\n",
    "    scaler = RobustScaler()\n",
    "    input_sequence = scaler.fit_transform(input_sequence)\n",
    "    \n",
    "    return input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31882bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elliott(x, p):\n",
    "    return (p * x) / (1 + K.abs(x))\n",
    "\n",
    "# Derivative of PEF\n",
    "def elliott_derivative(x, p):\n",
    "    return p / ((K.abs(x) + 1) ** 2)\n",
    "\n",
    "# Swish Activation Function\n",
    "def swish(x):\n",
    "    return x * K.sigmoid(x)\n",
    "\n",
    "# Custom PEF Activation Layer\n",
    "class PEFLayer(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(PEFLayer, self).__init__(activation, **kwargs)\n",
    "        self.p = K.variable(1.0)  # Initialize parameter p\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return elliott(inputs, self.p)\n",
    "\n",
    "# Build p-LSTM Model\n",
    "def build_p_lstm(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # p-LSTM Layer with PEF activation (named)\n",
    "    lstm_out = LSTM(32, return_sequences=False, kernel_regularizer=l2(0.01), name='lstm_layer')(inputs)\n",
    "    lstm_out = Dropout(0.5)(lstm_out)  # Dropout for regularization\n",
    "    lstm_out = PEFLayer(elliott)(lstm_out)\n",
    "    \n",
    "    # Fully Connected Layer with PEF activation (named)\n",
    "    dense1 = Dense(16, kernel_regularizer=l2(0.01), name='dense_layer')(lstm_out)\n",
    "    dense1 = Dropout(0.5)(dense1)\n",
    "    dense1 = PEFLayer(elliott)(dense1)\n",
    "    \n",
    "    # Swish Activation Layer\n",
    "    swish_out = Activation(swish)(dense1)\n",
    "    \n",
    "    # Sigmoid Output Layer for Binary Classification\n",
    "    outputs = Dense(1, activation=\"sigmoid\", name='output_layer')(swish_out)\n",
    "    \n",
    "    # Model outputs intermediate layers + final output\n",
    "    model = Model(inputs=inputs, outputs=[lstm_out, dense1, outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8094ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def dump_results_to_csv(df_results, method_name, output_dir=\"evaluation_results\"):\n",
    "    \"\"\"\n",
    "    Saves the evaluation results DataFrame to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        df_results (pd.DataFrame): DataFrame with evaluation results.\n",
    "        method_name (str): A name for the method to be used in the filename.\n",
    "        output_dir (str): Directory to save the results. Default is 'evaluation_results/'.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    file_path = os.path.join(output_dir, f\"{method_name}_results.csv\")\n",
    "    df_results.to_csv(file_path, index=False)\n",
    "    print(f\"Saved results to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a11a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fixed_time_method(user_labels):\n",
    "    results = []\n",
    "\n",
    "    for user_id, labels in user_labels.items():\n",
    "        # Predict all 1s for fixed-time baseline\n",
    "        predictions = np.ones_like(labels)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(labels, predictions, labels=[0, 1]).ravel()\n",
    "\n",
    "        # Compute metrics\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        results.append({\n",
    "            \"User\": user_id,\n",
    "            \"TPR\": tpr,\n",
    "            \"TNR\": tnr,\n",
    "            \"FPR\": fpr,\n",
    "            \"Weighted F1\": f1\n",
    "        })\n",
    "\n",
    "    # Create DataFrame and average row\n",
    "    df_results = pd.DataFrame(results)\n",
    "    avg_row = {\n",
    "        \"User\": \"Average\",\n",
    "        \"TPR\": df_results[\"TPR\"].mean(),\n",
    "        \"TNR\": df_results[\"TNR\"].mean(),\n",
    "        \"FPR\": df_results[\"FPR\"].mean(),\n",
    "        \"Weighted F1\": df_results[\"Weighted F1\"].mean()\n",
    "    }\n",
    "    df_results = pd.concat([df_results, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "    # Round for display\n",
    "    df_results_rounded = df_results.copy()\n",
    "    df_results_rounded[[\"TPR\", \"TNR\", \"FPR\", \"Weighted F1\"]] = df_results_rounded[\n",
    "        [\"TPR\", \"TNR\", \"FPR\", \"Weighted F1\"]\n",
    "    ].round(4)\n",
    "\n",
    "    # Display the results\n",
    "    print(\"\\n=== Fixed Time Method Evaluation ===\\n\")\n",
    "    print(df_results_rounded.to_string(index=False))\n",
    "\n",
    "    return df_results_rounded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d3fba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_baseline_avg_over_trials(user_inputs, user_labels, seed=42, trials=20):\n",
    "    np.random.seed(seed)\n",
    "    all_user_metrics = {}\n",
    "\n",
    "    for user, inputs in user_inputs.items():\n",
    "        labels = user_labels[user]\n",
    "        n_samples = len(labels)\n",
    "\n",
    "        metrics_per_trial = []\n",
    "\n",
    "        for _ in range(trials):\n",
    "            # Fully random 0 or 1 predictions (independent for each sample)\n",
    "            pred = np.random.choice([0, 1], size=n_samples)\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(labels, pred, labels=[0, 1]).ravel()\n",
    "\n",
    "            TPR = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            TNR = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "            FPR = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "            wF1 = f1_score(labels, pred, average='weighted')\n",
    "\n",
    "            metrics_per_trial.append((TPR, TNR, FPR, wF1))\n",
    "\n",
    "        # Compute average across all trials\n",
    "        metrics_array = np.array(metrics_per_trial)\n",
    "        avg_tpr, avg_tnr, avg_fpr, avg_wf1 = metrics_array.mean(axis=0)\n",
    "\n",
    "        all_user_metrics[user] = {\n",
    "            \"User\": user,\n",
    "            \"TPR\": avg_tpr,\n",
    "            \"TNR\": avg_tnr,\n",
    "            \"FPR\": avg_fpr,\n",
    "            \"Weighted F1\": avg_wf1\n",
    "        }\n",
    "\n",
    "    df_results = pd.DataFrame(list(all_user_metrics.values()))\n",
    "\n",
    "    # Add average row\n",
    "    avg_row = {\n",
    "        \"User\": \"Average\",\n",
    "        \"TPR\": df_results[\"TPR\"].mean(),\n",
    "        \"TNR\": df_results[\"TNR\"].mean(),\n",
    "        \"FPR\": df_results[\"FPR\"].mean(),\n",
    "        \"Weighted F1\": df_results[\"Weighted F1\"].mean()\n",
    "    }\n",
    "    df_results = pd.concat([df_results, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "    # Round for display\n",
    "    df_results_rounded = df_results.copy()\n",
    "    df_results_rounded[[\"TPR\", \"TNR\", \"FPR\", \"Weighted F1\"]] = df_results_rounded[\n",
    "        [\"TPR\", \"TNR\", \"FPR\", \"Weighted F1\"]\n",
    "    ].round(4)\n",
    "\n",
    "    # Display the results\n",
    "    print(\"\\n=== Fully Random Baseline (Averaged Over Trials) ===\\n\")\n",
    "    print(df_results_rounded.to_string(index=False))\n",
    "\n",
    "    return df_results_rounded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6d6d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, classification_report, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9446224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def evaluate_classical_models_with_distillation(user_inputs_full, user_inputs_reduced, user_labels, df_profiles):\n",
    "    results_rf, results_xgb, results_svc = [], [], []\n",
    "\n",
    "    for user, X_full in user_inputs_full.items():\n",
    "        cluster = df_profiles[df_profiles[\"User\"] == user][\"Cluster\"].values[0]\n",
    "        similar_users = [u for u in df_profiles[df_profiles[\"Cluster\"] == cluster][\"User\"] if u != user]\n",
    "\n",
    "        train_X_full, train_X_reduced, train_y = [], [], []\n",
    "        for u in similar_users:\n",
    "            if u in user_inputs_full and u in user_labels:\n",
    "                train_X_full.append(user_inputs_full[u])\n",
    "                train_X_reduced.append(user_inputs_reduced[u])\n",
    "                train_y.append(user_labels[u])\n",
    "\n",
    "        if not train_X_full:\n",
    "            print(f\"No training data for {user}\")\n",
    "            continue\n",
    "\n",
    "        train_X_full = np.vstack(train_X_full)\n",
    "        train_X_reduced = np.vstack(train_X_reduced)\n",
    "        train_y = np.hstack(train_y)\n",
    "\n",
    "        # Step 1: Train teacher classifiers on full features\n",
    "        neg, pos = np.bincount(train_y.astype(int))\n",
    "        scale_pos_weight = neg / pos if pos else 1\n",
    "\n",
    "        rf_teacher = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42).fit(train_X_full, train_y)\n",
    "        xgb_teacher = XGBClassifier(eval_metric='logloss', scale_pos_weight=scale_pos_weight, random_state=42).fit(train_X_full, train_y)\n",
    "        svc_teacher = SVC(probability=True, class_weight='balanced', random_state=42).fit(train_X_full, train_y)\n",
    "\n",
    "\n",
    "        soft_rf = rf_teacher.predict_proba(train_X_full)[:, 1]\n",
    "        soft_xgb = xgb_teacher.predict_proba(train_X_full)[:, 1]\n",
    "        soft_svc = svc_teacher.predict_proba(train_X_full)[:, 1]\n",
    "\n",
    "        # Step 2: Train student regressors on reduced features\n",
    "        rf_student = RandomForestRegressor(n_estimators=100, random_state=42).fit(train_X_reduced, soft_rf)\n",
    "        xgb_student = XGBRegressor(random_state=42).fit(train_X_reduced, soft_xgb)\n",
    "        svc_student = SVR().fit(train_X_reduced, soft_svc)\n",
    "\n",
    "        # Step 3: Evaluate student models on reduced test set\n",
    "        test_X_reduced = user_inputs_reduced[user]\n",
    "        true_y = user_labels[user]\n",
    "\n",
    "        student_models = {\n",
    "            \"Random Forest\": rf_student,\n",
    "            \"XGBoost\": xgb_student,\n",
    "            \"SVM\": svc_student\n",
    "        }\n",
    "\n",
    "        for model_name, student_model in student_models.items():\n",
    "            prob_pred = student_model.predict(test_X_reduced)\n",
    "            class_pred = (prob_pred >= 0.5).astype(int)  # thresholding\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(true_y, class_pred, labels=[0, 1]).ravel()\n",
    "            tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "            tnr = tn / (tn + fp) if (tn + fp) else 0\n",
    "            fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "            f1 = f1_score(true_y, class_pred, average='weighted')\n",
    "            auc = roc_auc_score(true_y, prob_pred)\n",
    "            acc = accuracy_score(true_y, class_pred)\n",
    "\n",
    "            row = {\n",
    "                \"User\": user,\n",
    "                \"TPR\": tpr,\n",
    "                \"TNR\": tnr,\n",
    "                \"FPR\": fpr,\n",
    "                \"Weighted F1\": f1,\n",
    "                \"AUC\": auc,\n",
    "                \"Accuracy\": acc\n",
    "            }\n",
    "\n",
    "            # Save model\n",
    "            model_folder = f\"dump/models_distilled/{model_name.lower().replace(' ', '_')}\"\n",
    "            os.makedirs(model_folder, exist_ok=True)\n",
    "            model_path = os.path.join(model_folder, f\"{user}.pkl\")\n",
    "            joblib.dump(student_model, model_path)\n",
    "\n",
    "            if model_name == \"Random Forest\":\n",
    "                results_rf.append(row)\n",
    "            elif model_name == \"XGBoost\":\n",
    "                results_xgb.append(row)\n",
    "            elif model_name == \"SVM\":\n",
    "                results_svc.append(row)\n",
    "\n",
    "    def finalize(df):\n",
    "        avg = {k: round(df[k].mean(), 4) for k in df.columns if k != \"User\"}\n",
    "        avg[\"User\"] = \"Average\"\n",
    "        return pd.concat([df, pd.DataFrame([avg])], ignore_index=True)\n",
    "\n",
    "    return finalize(pd.DataFrame(results_rf)), finalize(pd.DataFrame(results_xgb)), finalize(pd.DataFrame(results_svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aaa6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classical_models(user_inputs, user_labels, df_profiles):\n",
    "    results_rf = []\n",
    "    results_xgb = []\n",
    "    results_svc = []\n",
    "\n",
    "    for user, input_sequence in user_inputs.items():\n",
    "        cluster = df_profiles[df_profiles[\"User\"] == user][\"Cluster\"].values[0]\n",
    "        similar_users = [u for u in df_profiles[df_profiles[\"Cluster\"] == cluster][\"User\"] if u != user]\n",
    "\n",
    "        train_data = []\n",
    "        train_labels = []\n",
    "        for u in similar_users:\n",
    "            if u in user_inputs:\n",
    "                train_data.append(user_inputs[u])\n",
    "                train_labels.append(user_labels[u])\n",
    "\n",
    "        if not train_data:\n",
    "            print(f\"No training data available for {user}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        train_data = np.vstack(train_data)\n",
    "        train_labels = np.hstack(train_labels)\n",
    "\n",
    "        test_data = input_sequence\n",
    "        test_labels = user_labels[user]\n",
    "\n",
    "        models = {\n",
    "            \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "            \"SVM\": SVC(probability=True, random_state=42)\n",
    "        }\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            model.fit(train_data, train_labels)\n",
    "            y_pred = model.predict(test_data)\n",
    "            y_pred_prob = model.predict_proba(test_data)[:, 1]\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(test_labels, y_pred, labels=[0, 1]).ravel()\n",
    "            tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "            tnr = tn / (tn + fp) if (tn + fp) else 0\n",
    "            fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "            f1 = f1_score(test_labels, y_pred, average='weighted')\n",
    "            auc = roc_auc_score(test_labels, y_pred_prob)\n",
    "            acc = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "            row = {\n",
    "                \"User\": user,\n",
    "                \"TPR\": tpr,\n",
    "                \"TNR\": tnr,\n",
    "                \"FPR\": fpr,\n",
    "                \"Weighted F1\": f1,\n",
    "                \"AUC\": auc,\n",
    "                \"Accuracy\": acc\n",
    "            }\n",
    "\n",
    "            if model_name == \"Random Forest\":\n",
    "                results_rf.append(row)\n",
    "            elif model_name == \"XGBoost\":\n",
    "                results_xgb.append(row)\n",
    "            elif model_name == \"SVM\":\n",
    "                results_svc.append(row)\n",
    "\n",
    "    # Convert lists to DataFrames\n",
    "    df_rf = pd.DataFrame(results_rf)\n",
    "    df_xgb = pd.DataFrame(results_xgb)\n",
    "    df_svc = pd.DataFrame(results_svc)\n",
    "\n",
    "    # Add average row to each DataFrame\n",
    "    for df in [df_rf, df_xgb, df_svc]:\n",
    "        avg_row = {\n",
    "            \"User\": \"Average\",\n",
    "            \"TPR\": df[\"TPR\"].mean(),\n",
    "            \"TNR\": df[\"TNR\"].mean(),\n",
    "            \"FPR\": df[\"FPR\"].mean(),\n",
    "            \"Weighted F1\": df[\"Weighted F1\"].mean(),\n",
    "            \"AUC\": df[\"AUC\"].mean(),\n",
    "            \"Accuracy\": df[\"Accuracy\"].mean()\n",
    "        }\n",
    "        df.loc[len(df)] = avg_row\n",
    "\n",
    "    # Round metrics for readability\n",
    "    for df in [df_rf, df_xgb, df_svc]:\n",
    "        df.iloc[:, 1:] = df.iloc[:, 1:].round(4)\n",
    "\n",
    "    # Determine best model by average Weighted F1\n",
    "    avg_f1_scores = {\n",
    "        \"Random Forest\": df_rf.loc[df_rf[\"User\"] == \"Average\", \"Weighted F1\"].values[0],\n",
    "        \"XGBoost\": df_xgb.loc[df_xgb[\"User\"] == \"Average\", \"Weighted F1\"].values[0],\n",
    "        \"SVM\": df_svc.loc[df_svc[\"User\"] == \"Average\", \"Weighted F1\"].values[0]\n",
    "    }\n",
    "    best_model = max(avg_f1_scores, key=avg_f1_scores.get)\n",
    "\n",
    "    return df_rf, df_xgb, df_svc, best_model, avg_f1_scores[best_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c16218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_personalized_plstm(user_inputs, user_labels):\n",
    "    results = []\n",
    "\n",
    "    for user, input_sequence in user_inputs.items():\n",
    "        labels = user_labels[user]\n",
    "\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                input_sequence, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "            )\n",
    "        except ValueError:\n",
    "            print(f\"Skipping {user} due to insufficient class distribution.\")\n",
    "            continue\n",
    "\n",
    "        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "        model = build_p_lstm((X_train.shape[1], X_train.shape[2]))\n",
    "        model.compile(optimizer=Adam(0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_split=0.2,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        base_dir = \"dump/saved_models_emotion_personalized\"\n",
    "        user_folder = os.path.join(base_dir, f\"user_{user}\")\n",
    "        os.makedirs(user_folder, exist_ok=True)\n",
    "\n",
    "        model.save(os.path.join(user_folder, \"teacher_model\"), save_format=\"tf\")\n",
    "\n",
    "\n",
    "        print(f\"Saved teacher and student models for {user} in {user_folder}\")\n",
    "\n",
    "        _, _, y_pred_prob = model.predict(X_test)\n",
    "        y_pred_classes = (y_pred_prob.flatten() > 0.5).astype(int)\n",
    "\n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, y_pred_classes, labels=[0, 1]).ravel()\n",
    "        except ValueError:\n",
    "            tn = fp = fn = tp = 0\n",
    "\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "        f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "        auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        acc = accuracy_score(y_test, y_pred_classes)\n",
    "\n",
    "        results.append({\n",
    "            \"User\": user,\n",
    "            \"TPR\": tpr,\n",
    "            \"TNR\": tnr,\n",
    "            \"FPR\": fpr,\n",
    "            \"Weighted F1\": f1,\n",
    "            \"AUC\": auc,\n",
    "            \"Accuracy\": acc\n",
    "        })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    avg_row = {\n",
    "        \"User\": \"Average\",\n",
    "        \"TPR\": df_results[\"TPR\"].mean(),\n",
    "        \"TNR\": df_results[\"TNR\"].mean(),\n",
    "        \"FPR\": df_results[\"FPR\"].mean(),\n",
    "        \"Weighted F1\": df_results[\"Weighted F1\"].mean(),\n",
    "        \"AUC\": df_results[\"AUC\"].mean(),\n",
    "        \"Accuracy\": df_results[\"Accuracy\"].mean()\n",
    "    }\n",
    "    df_results.loc[len(df_results)] = avg_row\n",
    "    df_results.iloc[:, 1:] = df_results.iloc[:, 1:].round(4)\n",
    "\n",
    "    print(\"\\n=== Personalized p-LSTM Evaluation ===\\n\")\n",
    "    print(df_results.to_string(index=False))\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "760cdce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_aggregate_p_lstm(user_inputs, user_labels):\n",
    "    results = []\n",
    "\n",
    "    for user, test_data in user_inputs.items():\n",
    "        test_labels = user_labels[user]\n",
    "\n",
    "        # Use data from all other users for training\n",
    "        train_data = []\n",
    "        train_labels = []\n",
    "        for other_user, other_data in user_inputs.items():\n",
    "            if other_user != user:\n",
    "                train_data.append(other_data)\n",
    "                train_labels.append(user_labels[other_user])\n",
    "\n",
    "        if not train_data:\n",
    "            print(f\"No training data available for {user}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        train_data = np.vstack(train_data)\n",
    "        train_labels = np.hstack(train_labels)\n",
    "\n",
    "        print(f\"\\nTraining aggregate model for user {user} using data from all other users\")\n",
    "        print(f\"Train samples: {len(train_data)}, Test samples: {len(test_data)}\")\n",
    "        print(f\"Train dist: {np.bincount(train_labels.astype(int))}, Test dist: {np.bincount(test_labels.astype(int))}\")\n",
    "\n",
    "        # Reshape for LSTM [samples, timesteps, features]\n",
    "        train_data = train_data.reshape((train_data.shape[0], 1, train_data.shape[1]))\n",
    "        test_data = test_data.reshape((test_data.shape[0], 1, test_data.shape[1]))\n",
    "\n",
    "        # Build and compile model\n",
    "        model = build_p_lstm((train_data.shape[1], train_data.shape[2]))\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss=BinaryCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        # Compute class weights\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight=\"balanced\",\n",
    "            classes=np.unique(train_labels),\n",
    "            y=train_labels\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(\n",
    "            train_data, train_labels,\n",
    "            validation_split=0.2,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        base_dir = \"dump/saved_models_aggregate\"\n",
    "        user_folder = os.path.join(base_dir, f\"user_{user}\")\n",
    "        os.makedirs(user_folder, exist_ok=True)\n",
    "\n",
    "        model.save(os.path.join(user_folder, \"teacher_model\"), save_format=\"tf\")\n",
    "        # Evaluate\n",
    "        _, _, y_pred_prob = model.predict(test_data)\n",
    "        y_pred_classes = (y_pred_prob.flatten() > 0.5).astype(int)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(test_labels, y_pred_classes, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "        f1 = f1_score(test_labels, y_pred_classes, average='weighted')\n",
    "        auc = roc_auc_score(test_labels, y_pred_prob)\n",
    "        acc = accuracy_score(test_labels, y_pred_classes)\n",
    "\n",
    "        results.append({\n",
    "            \"User\": user,\n",
    "            \"TPR\": tpr,\n",
    "            \"TNR\": tnr,\n",
    "            \"FPR\": fpr,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Weighted F1\": f1,\n",
    "            \"AUC\": auc\n",
    "        })\n",
    "\n",
    "    # Create dataframe\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    # Add average row\n",
    "    avg_row = {\n",
    "        \"User\": \"Average\",\n",
    "        \"TPR\": df_results[\"TPR\"].mean(),\n",
    "        \"TNR\": df_results[\"TNR\"].mean(),\n",
    "        \"FPR\": df_results[\"FPR\"].mean(),\n",
    "        \"Accuracy\": df_results[\"Accuracy\"].mean(),\n",
    "        \"Weighted F1\": df_results[\"Weighted F1\"].mean(),\n",
    "        \"AUC\": df_results[\"AUC\"].mean()\n",
    "    }\n",
    "    df_results.loc[len(df_results)] = avg_row\n",
    "\n",
    "    # Round for readability\n",
    "    df_results.iloc[:, 1:] = df_results.iloc[:, 1:].round(4)\n",
    "\n",
    "    print(\"\\n=== Aggregate p-LSTM Evaluation ===\\n\")\n",
    "    print(df_results.to_string(index=False))\n",
    "\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a5adcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gender_based_plstm(user_inputs, user_labels, df_profiles):\n",
    "    results = []\n",
    "\n",
    "    for user, input_sequence in user_inputs.items():\n",
    "        # Get current user's gender\n",
    "        gender = df_profiles[df_profiles[\"User\"] == user][\"Gender\"].values[0]\n",
    "\n",
    "        # Get other users with same gender (excluding current user)\n",
    "        same_gender_users = df_profiles[(df_profiles[\"Gender\"] == gender) & (df_profiles[\"User\"] != user)][\"User\"].tolist()\n",
    "        print(f\"User{user} trained on {same_gender_users}\")\n",
    "\n",
    "        train_data, train_labels = [], []\n",
    "        for u in same_gender_users:\n",
    "            if u in user_inputs:\n",
    "                train_data.append(user_inputs[u])\n",
    "                train_labels.append(user_labels[u])\n",
    "\n",
    "        if not train_data:\n",
    "            print(f\"Skipping {user} — No same-gender training data available.\")\n",
    "            continue\n",
    "\n",
    "        train_data = np.vstack(train_data)\n",
    "        train_labels = np.hstack(train_labels)\n",
    "\n",
    "        test_data = input_sequence\n",
    "        test_labels = user_labels[user]\n",
    "\n",
    "        print(f\"\\nTraining {user} using gender-based users: {same_gender_users}\")\n",
    "        print(f\"Train samples: {len(train_data)}, Test samples: {len(test_data)}\")\n",
    "        print(f\"Class distribution — Train: {np.bincount(train_labels.astype(int))}, Test: {np.bincount(test_labels.astype(int))}\")\n",
    "\n",
    "        # Reshape for LSTM: [samples, timesteps, features]\n",
    "        train_data = train_data.reshape((train_data.shape[0], 1, train_data.shape[1]))\n",
    "        test_data = test_data.reshape((test_data.shape[0], 1, test_data.shape[1]))\n",
    "\n",
    "        model = build_p_lstm((train_data.shape[1], train_data.shape[2]))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss=BinaryCrossentropy(),\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight=\"balanced\",\n",
    "            classes=np.unique(train_labels),\n",
    "            y=train_labels\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        model.fit(\n",
    "            train_data, train_labels,\n",
    "            validation_split=0.2,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            class_weight=class_weights,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        base_dir = \"dump/saved_models_gender\"\n",
    "        user_folder = os.path.join(base_dir, f\"user_{user}\")\n",
    "        os.makedirs(user_folder, exist_ok=True)\n",
    "\n",
    "        model.save(os.path.join(user_folder, \"teacher_model\"), save_format=\"tf\")\n",
    "\n",
    "        # Evaluation\n",
    "        _, _, y_pred_prob = model.predict(test_data)\n",
    "        y_pred_classes = (y_pred_prob.flatten() > 0.5).astype(int)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(test_labels, y_pred_classes, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "        f1 = f1_score(test_labels, y_pred_classes, average='weighted')\n",
    "        auc = roc_auc_score(test_labels, y_pred_prob)\n",
    "        acc = accuracy_score(test_labels, y_pred_classes)\n",
    "\n",
    "        results.append({\n",
    "            \"User\": user,\n",
    "            \"TPR\": tpr,\n",
    "            \"TNR\": tnr,\n",
    "            \"FPR\": fpr,\n",
    "            \"Weighted F1\": f1,\n",
    "            \"AUC\": auc,\n",
    "            \"Accuracy\": acc\n",
    "        })\n",
    "\n",
    "    df_result = pd.DataFrame(results)\n",
    "\n",
    "    # Add average row\n",
    "    avg_row = {\n",
    "        \"User\": \"Average\",\n",
    "        \"TPR\": df_result[\"TPR\"].mean(),\n",
    "        \"TNR\": df_result[\"TNR\"].mean(),\n",
    "        \"FPR\": df_result[\"FPR\"].mean(),\n",
    "        \"Weighted F1\": df_result[\"Weighted F1\"].mean(),\n",
    "        \"AUC\": df_result[\"AUC\"].mean(),\n",
    "        \"Accuracy\": df_result[\"Accuracy\"].mean()\n",
    "    }\n",
    "    df_result.loc[len(df_result)] = avg_row\n",
    "    df_result.iloc[:, 1:] = df_result.iloc[:, 1:].round(4)\n",
    "\n",
    "    print(\"\\n=== Gender Based p-LSTM Evaluation ===\\n\")\n",
    "    print(df_result.to_string(index=False))\n",
    "\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef9c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_age_based_plstm(user_inputs, user_labels, df_profiles):\n",
    "    results = []\n",
    "\n",
    "    for user, input_sequence in user_inputs.items():\n",
    "        # Get current user's age bin\n",
    "        age_bin = df_profiles[df_profiles[\"User\"] == user][\"AgeBin\"].values[0]\n",
    "\n",
    "        # Get other users in same age bin (excluding current user)\n",
    "        same_age_users = df_profiles[(df_profiles[\"AgeBin\"] == age_bin) & (df_profiles[\"User\"] != user)][\"User\"].tolist()\n",
    "\n",
    "        train_data, train_labels = [], []\n",
    "        for u in same_age_users:\n",
    "            if u in user_inputs:\n",
    "                train_data.append(user_inputs[u])\n",
    "                train_labels.append(user_labels[u])\n",
    "\n",
    "        if not train_data:\n",
    "            print(f\"Skipping {user} — No training data available in same AgeBin.\")\n",
    "            continue\n",
    "\n",
    "        train_data = np.vstack(train_data)\n",
    "        train_labels = np.hstack(train_labels)\n",
    "\n",
    "        test_data = input_sequence\n",
    "        test_labels = user_labels[user]\n",
    "\n",
    "        print(f\"\\nTraining {user} using age-based users: {same_age_users}\")\n",
    "        print(f\"Train samples: {len(train_data)}, Test samples: {len(test_data)}\")\n",
    "        print(f\"Class distribution — Train: {np.bincount(train_labels.astype(int))}, Test: {np.bincount(test_labels.astype(int))}\")\n",
    "\n",
    "        # Reshape for LSTM: [samples, timesteps, features]\n",
    "        train_data = train_data.reshape((train_data.shape[0], 1, train_data.shape[1]))\n",
    "        test_data = test_data.reshape((test_data.shape[0], 1, test_data.shape[1]))\n",
    "\n",
    "        model = build_p_lstm((train_data.shape[1], train_data.shape[2]))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss=BinaryCrossentropy(),\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight=\"balanced\",\n",
    "            classes=np.unique(train_labels),\n",
    "            y=train_labels\n",
    "        )\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        model.fit(\n",
    "            train_data, train_labels,\n",
    "            validation_split=0.2,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            class_weight=class_weights,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        base_dir = \"dump/saved_models_age\"\n",
    "        user_folder = os.path.join(base_dir, f\"user_{user}\")\n",
    "        os.makedirs(user_folder, exist_ok=True)\n",
    "\n",
    "        model.save(os.path.join(user_folder, \"teacher_model\"), save_format=\"tf\")\n",
    "\n",
    "        # Evaluation\n",
    "        _, _, y_pred_prob = model.predict(test_data)\n",
    "        y_pred_classes = (y_pred_prob.flatten() > 0.5).astype(int)\n",
    "\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(test_labels, y_pred_classes, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "        f1 = f1_score(test_labels, y_pred_classes, average='weighted')\n",
    "        auc = roc_auc_score(test_labels, y_pred_prob)\n",
    "        acc = accuracy_score(test_labels, y_pred_classes)\n",
    "\n",
    "        results.append({\n",
    "            \"User\": user,\n",
    "            \"TPR\": tpr,\n",
    "            \"TNR\": tnr,\n",
    "            \"FPR\": fpr,\n",
    "            \"Weighted F1\": f1,\n",
    "            \"AUC\": auc,\n",
    "            \"Accuracy\": acc\n",
    "        })\n",
    "\n",
    "    df_result = pd.DataFrame(results)\n",
    "\n",
    "    # Add average row\n",
    "    avg_row = {\n",
    "        \"User\": \"Average\",\n",
    "        \"TPR\": df_result[\"TPR\"].mean(),\n",
    "        \"TNR\": df_result[\"TNR\"].mean(),\n",
    "        \"FPR\": df_result[\"FPR\"].mean(),\n",
    "        \"Weighted F1\": df_result[\"Weighted F1\"].mean(),\n",
    "        \"AUC\": df_result[\"AUC\"].mean(),\n",
    "        \"Accuracy\": df_result[\"Accuracy\"].mean()\n",
    "    }\n",
    "    df_result.loc[len(df_result)] = avg_row\n",
    "    df_result.iloc[:, 1:] = df_result.iloc[:, 1:].round(4)\n",
    "\n",
    "    print(\"\\n=== Age Based p-LSTM Evaluation ===\\n\")\n",
    "    print(df_result.to_string(index=False))\n",
    "\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    user_reports = []\n",
    "\n",
    "    # User profiles with pre-defined clusters\n",
    "    df_profiles = pd.DataFrame({\n",
    "        \"User\": [\"User1\", \"User2\", \"User3\", \"User4\", \"User5\", \"User6\", \"User8\", \"User9\", \"User10\",\n",
    "                \"User11\", \"User12\", \"User13\", \"User14\", \"User15\", \"User16\", \"User17\", \"User18\",\n",
    "                \"User19\", \"User20\", \"User21\", \"User22\", \"User23\", \"User24\", \"User25\", \"User26\",\n",
    "                \"User27\", \"User28\", \"User29\", \"User30\"],\n",
    "        \"Cluster\": [0, 0, 0, 1, 1, 0, 0, 0, 0, \n",
    "                   0, 0, 0, 0, 0, 0, 0, 1,\n",
    "                   0, 0, 0, 0, 0, 0, 0, 1,\n",
    "                   0, 0, 1, 0]\n",
    "    })\n",
    "\n",
    "    df_participant = pd.read_excel(\"case_dataset-master/case_dataset-master/metadata/participants.xlsx\")\n",
    "    #print(df_participant.columns.tolist())\n",
    "\n",
    "    df_participant.drop(columns=[\"Video Sequence Used \"], inplace=True)\n",
    "    df_participant = df_participant[df_participant[\"Participant-ID\"] != 7]\n",
    "    df_profiles[\"Participant-ID\"] = df_profiles[\"User\"].str.extract(r'(\\d+)').astype(int)\n",
    "    df_profiles = df_profiles.merge(df_participant, on=\"Participant-ID\", how=\"left\")\n",
    "    df_profiles.rename(columns={\"Sex\": \"Gender\", \"Age-Group\": \"AgeGroup\"}, inplace=True)\n",
    "    df_profiles.drop(columns=[\"Participant-ID\"], inplace=True)\n",
    "   # print(df_profiles)\n",
    "   # print(df_profiles.columns)\n",
    "    age_counts = df_profiles[\"AgeGroup\"].value_counts().sort_index()\n",
    "\n",
    "    # Plot age distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(age_counts.index.astype(str), age_counts.values)\n",
    "    plt.xlabel(\"Age\")\n",
    "    plt.ylabel(\"Number of Users\")\n",
    "    plt.title(\"Age-wise User Distribution\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    def convert_age_range_to_num(age_str):\n",
    "        if pd.isna(age_str):\n",
    "            return None\n",
    "        if '-' in str(age_str):\n",
    "            low, high = age_str.split('-')\n",
    "            return (int(low) + int(high)) / 2\n",
    "        try:\n",
    "            return float(age_str)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df_profiles[\"AgeGroup\"] = df_profiles[\"AgeGroup\"].apply(convert_age_range_to_num)\n",
    "    bins = [22, 25, 30, 37]\n",
    "    labels = [\"22-25\", \"26-30\", \"31-37\"]\n",
    "    df_profiles[\"AgeBin\"] = pd.cut(df_profiles[\"AgeGroup\"], bins=bins, labels=labels, include_lowest=True)\n",
    "    age_bin_counts = df_profiles[\"AgeBin\"].value_counts().sort_index()\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.bar(age_bin_counts.index.astype(str), age_bin_counts.values, color='skyblue')\n",
    "    plt.xlabel(\"Age Group\")\n",
    "    plt.ylabel(\"Number of Users\")\n",
    "    plt.title(\"Number of Users per Age Group\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print counts\n",
    "    print(age_bin_counts)\n",
    "\n",
    "\n",
    "\n",
    "    # Preprocess data for all users\n",
    "    user_inputs = {}\n",
    "    user_labels = {}\n",
    "    for i in range(1, 31):\n",
    "        user_id = f\"User{i}\"\n",
    "        # Skip User7 which doesn't exist in your list\n",
    "        if i == 7:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            physio_file = f\"case_dataset-master/case_dataset-master/data/raw/physiological/sub{i}_DAQ.txt\"\n",
    "            \n",
    "            # Load only physiological data\n",
    "            df_physio = load_data(physio_file)\n",
    "            \n",
    "            # Segment data (now only needs physio data)\n",
    "            segmented_data = segment_data(df_physio)\n",
    "            \n",
    "            # Compute change scores\n",
    "            reduced_physio = segmented_data[['ECG_mean', 'BVP_mean', 'GSR_mean', 'Resp_mean', 'Skin_temp_mean', 'EMG_mean']].values\n",
    "            from scipy.stats import zscore\n",
    "\n",
    "            reduced_physio_zscored = zscore(reduced_physio, axis=0)\n",
    "\n",
    "            change_scores = compute_rulsif_change_scores(reduced_physio_zscored)\n",
    "            \n",
    "            # Label opportune moments\n",
    "            opportune_moments = label_opportune_moments(change_scores)\n",
    "            labels = np.zeros(len(segmented_data))\n",
    "            labels[opportune_moments] = 1\n",
    "            \n",
    "            # Prepare input sequence\n",
    "            input_sequence = prepare_input(segmented_data, change_scores)\n",
    "            \n",
    "            # Only keep samples where we have all data\n",
    "            valid_indices = ~np.isnan(input_sequence).any(axis=1)\n",
    "            input_sequence = input_sequence[valid_indices]\n",
    "            labels = labels[valid_indices]\n",
    "            \n",
    "            user_inputs[user_id] = input_sequence\n",
    "            user_labels[user_id] = labels\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Data for {user_id} not found. Skipping...\")\n",
    "            continue\n",
    "    \n",
    "    # df_fixed_results = evaluate_fixed_time_method(user_labels)\n",
    "    # dump_results_to_csv(df_fixed_results, method_name=\"fixed_time\")\n",
    "    # df_random_results = random_baseline_avg_over_trials(user_inputs, user_labels)\n",
    "    # dump_results_to_csv(df_random_results, method_name=\"random_time\")\n",
    "    # df_rf, df_xgb, df_svc, best_model, best_score = evaluate_classical_models(user_inputs, user_labels, df_profiles)\n",
    "    # dump_results_to_csv(df_rf, method_name=\"random_forest\")\n",
    "    # dump_results_to_csv(df_xgb, method_name=\"xgb\")\n",
    "    # dump_results_to_csv(df_svc, method_name=\"svc\")\n",
    "\n",
    "    # print(\"=== Random Forest Results ===\")\n",
    "    # print(df_rf.to_string(index=False))\n",
    "\n",
    "    # print(\"\\n=== XGBoost Results ===\")\n",
    "    # print(df_xgb.to_string(index=False))\n",
    "\n",
    "    # print(\"\\n=== SVM Results ===\")\n",
    "    # print(df_svc.to_string(index=False))\n",
    "\n",
    "    # print(f\"\\nBest model overall: {best_model} with Average Weighted F1 = {best_score:.4f}\")\n",
    "\n",
    "    #df_result = evaluate_personalized_plstm(user_inputs, user_labels)\n",
    "    # dump_results_to_csv(df_result, method_name=\"personalized_plstm\")\n",
    "    #df_result = evaluate_aggregate_p_lstm(user_inputs, user_labels)\n",
    "    # dump_results_to_csv(df_result, method_name=\"aggregate_plstm\")\n",
    "    df_result = evaluate_gender_based_plstm(user_inputs, user_labels, df_profiles)\n",
    "    # dump_results_to_csv(df_result, method_name=\"gender_based_plstm\")\n",
    "    #df_result = evaluate_age_based_plstm(user_inputs, user_labels, df_profiles)\n",
    "    # dump_results_to_csv(df_result, method_name=\"age_based_plstm\")\n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1173ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    user_reports = []\n",
    "\n",
    "    # User profiles with pre-defined clusters\n",
    "    df_profiles = pd.DataFrame({\n",
    "        \"User\": [\"User1\", \"User2\", \"User3\", \"User4\", \"User5\", \"User6\", \"User8\", \"User9\", \"User10\",\n",
    "                \"User11\", \"User12\", \"User13\", \"User14\", \"User15\", \"User16\", \"User17\", \"User18\",\n",
    "                \"User19\", \"User20\", \"User21\", \"User22\", \"User23\", \"User24\", \"User25\", \"User26\",\n",
    "                \"User27\", \"User28\", \"User29\", \"User30\"],\n",
    "        \"Cluster\": [0, 0, 0, 1, 1, 0, 0, 0, 0, \n",
    "                   0, 0, 0, 0, 0, 0, 0, 1,\n",
    "                   0, 0, 0, 0, 0, 0, 0, 1,\n",
    "                   0, 0, 1, 0]\n",
    "    })\n",
    "\n",
    "    df_participant = pd.read_excel(\"case_dataset-master/case_dataset-master/metadata/participants.xlsx\")\n",
    "    #print(df_participant.columns.tolist())\n",
    "\n",
    "    df_participant.drop(columns=[\"Video Sequence Used \"], inplace=True)\n",
    "    df_participant = df_participant[df_participant[\"Participant-ID\"] != 7]\n",
    "    df_profiles[\"Participant-ID\"] = df_profiles[\"User\"].str.extract(r'(\\d+)').astype(int)\n",
    "    df_profiles = df_profiles.merge(df_participant, on=\"Participant-ID\", how=\"left\")\n",
    "    df_profiles.rename(columns={\"Sex\": \"Gender\", \"Age-Group\": \"AgeGroup\"}, inplace=True)\n",
    "    df_profiles.drop(columns=[\"Participant-ID\"], inplace=True)\n",
    "   # print(df_profiles)\n",
    "   # print(df_profiles.columns)\n",
    "    age_counts = df_profiles[\"AgeGroup\"].value_counts().sort_index()\n",
    "\n",
    "    user_inputs_full = {}     # For teacher models — full features\n",
    "    user_inputs_reduced = {}  # For student models — reduced features\n",
    "    user_labels = {}          # Binary labels for opportune moments\n",
    "\n",
    "    for i in range(1, 31):\n",
    "        user_id = f\"User{i}\"\n",
    "        \n",
    "        if i == 7:\n",
    "            continue  # Skipping User7 if data doesn't exist\n",
    "        \n",
    "        try:\n",
    "            physio_file = f\"case_dataset-master/case_dataset-master/data/raw/physiological/sub{i}_DAQ.txt\"\n",
    "            df_physio = load_data(physio_file)\n",
    "            segmented_data = segment_data(df_physio)\n",
    "\n",
    "            # Use reduced input features (GSR, BVP, Skin_temp) to compute change scores\n",
    "            reduced_physio = segmented_data[['ECG_mean', 'BVP_mean', 'GSR_mean', 'Resp_mean', 'Skin_temp_mean', 'EMG_mean']].values\n",
    "\n",
    "            change_scores = compute_rulsif_change_scores(reduced_physio)\n",
    "\n",
    "            # Generate labels for opportune moments\n",
    "            opportune_moments = label_opportune_moments(change_scores)\n",
    "            labels = np.zeros(len(segmented_data))\n",
    "            labels[opportune_moments] = 1\n",
    "\n",
    "            # Prepare inputs using your defined functions\n",
    "            input_full = prepare_input(segmented_data.copy(), change_scores)         # 15 features + score\n",
    "            \n",
    "            reduced_physio = segmented_data[['BVP_mean', 'GSR_mean', 'Skin_temp_mean']].values\n",
    "            change_scores = compute_rulsif_change_scores(reduced_physio)\n",
    "            input_reduced = prepare_input_student(segmented_data.copy(), change_scores)  # 7 features + score\n",
    "\n",
    "            # Filter out invalid (NaN) entries in both input and labels\n",
    "            valid_mask = ~np.isnan(input_full).any(axis=1) & ~np.isnan(input_reduced).any(axis=1)\n",
    "            \n",
    "            user_inputs_full[user_id] = input_full[valid_mask]\n",
    "            user_inputs_reduced[user_id] = input_reduced[valid_mask]\n",
    "            user_labels[user_id] = labels[valid_mask]\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Data for {user_id} not found. Skipping...\")\n",
    "            continue\n",
    "    rf_results, xgb_results, svc_results = evaluate_classical_models_with_distillation(\n",
    "        user_inputs_full, user_inputs_reduced, user_labels, df_profiles\n",
    "    )\n",
    "\n",
    "    rf_results.to_csv(\"rf_distilled_results.csv\", index=False)\n",
    "    xgb_results.to_csv(\"xgb_distilled_results.csv\", index=False)\n",
    "    svc_results.to_csv(\"svm_distilled_results.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    \n",
    "    user_reports = []\n",
    "\n",
    "    # User profiles with pre-defined clusters\n",
    "    df_profiles = pd.DataFrame({\n",
    "        \"User\": [\"User1\", \"User2\", \"User3\", \"User4\", \"User5\", \"User6\", \"User8\", \"User9\", \"User10\",\n",
    "                \"User11\", \"User12\", \"User13\", \"User14\", \"User15\", \"User16\", \"User17\", \"User18\",\n",
    "                \"User19\", \"User20\", \"User21\", \"User22\", \"User23\", \"User24\", \"User25\", \"User26\",\n",
    "                \"User27\", \"User28\", \"User29\", \"User30\"],\n",
    "        \"Cluster\": [0, 0, 0, 1, 1, 0, 0, 0, 0, \n",
    "                   0, 0, 0, 0, 0, 0, 0, 1,\n",
    "                   0, 0, 0, 0, 0, 0, 0, 1,\n",
    "                   0, 0, 1, 0]\n",
    "    })\n",
    "\n",
    "    df_participant = pd.read_excel(\"case_dataset-master/case_dataset-master/metadata/participants.xlsx\")\n",
    "    #print(df_participant.columns.tolist())\n",
    "\n",
    "    df_participant.drop(columns=[\"Video Sequence Used \"], inplace=True)\n",
    "    df_participant = df_participant[df_participant[\"Participant-ID\"] != 7]\n",
    "    df_profiles[\"Participant-ID\"] = df_profiles[\"User\"].str.extract(r'(\\d+)').astype(int)\n",
    "    df_profiles = df_profiles.merge(df_participant, on=\"Participant-ID\", how=\"left\")\n",
    "    df_profiles.rename(columns={\"Sex\": \"Gender\", \"Age-Group\": \"AgeGroup\"}, inplace=True)\n",
    "    df_profiles.drop(columns=[\"Participant-ID\"], inplace=True)\n",
    "   # print(df_profiles)\n",
    "   # print(df_profiles.columns)\n",
    "    age_counts = df_profiles[\"AgeGroup\"].value_counts().sort_index()\n",
    "\n",
    "    # Plot age distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(age_counts.index.astype(str), age_counts.values)\n",
    "    plt.xlabel(\"Age\")\n",
    "    plt.ylabel(\"Number of Users\")\n",
    "    plt.title(\"Age-wise User Distribution\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    def convert_age_range_to_num(age_str):\n",
    "        if pd.isna(age_str):\n",
    "            return None\n",
    "        if '-' in str(age_str):\n",
    "            low, high = age_str.split('-')\n",
    "            return (int(low) + int(high)) / 2\n",
    "        try:\n",
    "            return float(age_str)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df_profiles[\"AgeGroup\"] = df_profiles[\"AgeGroup\"].apply(convert_age_range_to_num)\n",
    "    bins = [22, 25, 30, 37]\n",
    "    labels = [\"22-25\", \"26-30\", \"31-37\"]\n",
    "    df_profiles[\"AgeBin\"] = pd.cut(df_profiles[\"AgeGroup\"], bins=bins, labels=labels, include_lowest=True)\n",
    "    age_bin_counts = df_profiles[\"AgeBin\"].value_counts().sort_index()\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.bar(age_bin_counts.index.astype(str), age_bin_counts.values, color='skyblue')\n",
    "    plt.xlabel(\"Age Group\")\n",
    "    plt.ylabel(\"Number of Users\")\n",
    "    plt.title(\"Number of Users per Age Group\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print counts\n",
    "    print(age_bin_counts)\n",
    "\n",
    "\n",
    "\n",
    "    # Preprocess data for all users\n",
    "    user_inputs = {}\n",
    "    user_labels = {}\n",
    "    for i in range(1, 31):\n",
    "        user_id = f\"User{i}\"\n",
    "        # Skip User7 which doesn't exist in your list\n",
    "        if i == 7:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            physio_file = f\"case_dataset-master/case_dataset-master/data/raw/physiological/sub{i}_DAQ.txt\"\n",
    "            \n",
    "            # Load only physiological data\n",
    "            df_physio = load_data(physio_file)\n",
    "            \n",
    "            # Segment data (now only needs physio data)\n",
    "            segmented_data = segment_data(df_physio)\n",
    "            \n",
    "            # Compute change scores\n",
    "            reduced_physio = segmented_data[['ECG_mean', 'BVP_mean', 'GSR_mean', 'Resp_mean', 'Skin_temp_mean', 'EMG_mean']].values\n",
    "\n",
    "            change_scores = compute_rulsif_change_scores(reduced_physio)\n",
    "            \n",
    "            # Label opportune moments\n",
    "            opportune_moments = label_opportune_moments(change_scores)\n",
    "            labels = np.zeros(len(segmented_data))\n",
    "            labels[opportune_moments] = 1\n",
    "            \n",
    "            # Prepare input sequence\n",
    "            input_sequence = prepare_input(segmented_data, change_scores)\n",
    "            \n",
    "            # Only keep samples where we have all data\n",
    "            valid_indices = ~np.isnan(input_sequence).any(axis=1)\n",
    "            input_sequence = input_sequence[valid_indices]\n",
    "            labels = labels[valid_indices]\n",
    "            \n",
    "            user_inputs[user_id] = input_sequence\n",
    "            user_labels[user_id] = labels\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Data for {user_id} not found. Skipping...\")\n",
    "            continue\n",
    "    \n",
    "    # df_fixed_results = evaluate_fixed_time_method(user_labels)\n",
    "    # dump_results_to_csv(df_fixed_results, method_name=\"fixed_time\")\n",
    "    # df_random_results = random_baseline_avg_over_trials(user_inputs, user_labels)\n",
    "    # dump_results_to_csv(df_random_results, method_name=\"random_time\")\n",
    "    # df_rf, df_xgb, df_svc, best_model, best_score = evaluate_classical_models(user_inputs, user_labels, df_profiles)\n",
    "    # dump_results_to_csv(df_rf, method_name=\"random_forest\")\n",
    "    # dump_results_to_csv(df_xgb, method_name=\"xgb\")\n",
    "    # dump_results_to_csv(df_svc, method_name=\"svc\")\n",
    "\n",
    "    # print(\"=== Random Forest Results ===\")\n",
    "    # print(df_rf.to_string(index=False))\n",
    "\n",
    "    # print(\"\\n=== XGBoost Results ===\")\n",
    "    # print(df_xgb.to_string(index=False))\n",
    "\n",
    "    # print(\"\\n=== SVM Results ===\")\n",
    "    # print(df_svc.to_string(index=False))\n",
    "\n",
    "    # print(f\"\\nBest model overall: {best_model} with Average Weighted F1 = {best_score:.4f}\")\n",
    "\n",
    "    df_result = evaluate_personalized_plstm(user_inputs, user_labels)\n",
    "    # dump_results_to_csv(df_result, method_name=\"personalized_plstm\")\n",
    "    #df_result = evaluate_aggregate_p_lstm(user_inputs, user_labels)\n",
    "    #3 dump_results_to_csv(df_result, method_name=\"aggregate_plstm\")\n",
    "    #df_result = evaluate_gender_based_plstm(user_inputs, user_labels, df_profiles)\n",
    "    # dump_results_to_csv(df_result, method_name=\"gender_based_plstm\")\n",
    "    #df_result = evaluate_age_based_plstm(user_inputs, user_labels, df_profiles)\n",
    "    # dump_results_to_csv(df_result, method_name=\"age_based_plstm\")\n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YO",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
