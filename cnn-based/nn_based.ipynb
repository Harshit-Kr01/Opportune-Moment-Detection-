{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fee803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Activation, Dropout, Bidirectional, Multiply, Flatten, Lambda,RepeatVector, Permute \n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, GlobalAveragePooling1D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.signal import resample, butter, filtfilt, welch\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "import csv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802db3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for sampling rates\n",
    "PHYSIO_SAMPLING_RATE = 1000  # Hz\n",
    "VALENCE_SAMPLING_RATE = 20    # Hz\n",
    "DOWNSAMPLE_FACTOR = PHYSIO_SAMPLING_RATE // VALENCE_SAMPLING_RATE  # 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ee55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load physiological data with proper downsampling\n",
    "def load_data(file_path):\n",
    "    columns = [\"time\", \"ECG\", \"BVP\", \"GSR\", \"Resp\", \"Skin_Temp\", \"EMG_z\", \"EMG_c\", \"EMG_t\"]\n",
    "    \n",
    "    # Read all data first\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", names=columns)\n",
    "    \n",
    "    # Downsample physiological data to match valence-arousal sampling rate\n",
    "    downsampled_df = df.iloc[::DOWNSAMPLE_FACTOR, :].copy()\n",
    "    \n",
    "    # Reset time to new sampling rate\n",
    "    downsampled_df[\"time\"] = np.arange(len(downsampled_df)) / VALENCE_SAMPLING_RATE\n",
    "    \n",
    "    return downsampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74691dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment into 5-second windows with proper alignment\n",
    "def segment_data(physio_df, window_size=5):  # Removed valence_df parameter\n",
    "    # Calculate number of samples per window\n",
    "    samples_per_window = window_size * VALENCE_SAMPLING_RATE\n",
    "    \n",
    "    # Segment physiological data only\n",
    "    segments = []\n",
    "    for i in range(0, len(physio_df), samples_per_window):\n",
    "        segment = physio_df.iloc[i:i+samples_per_window]\n",
    "        if len(segment) == samples_per_window:  # only complete segments\n",
    "            # Calculate time-domain features\n",
    "            features = {\n",
    "                \"time\": segment[\"time\"].mean(),\n",
    "                \"ECG_mean\": segment[\"ECG\"].mean(),\n",
    "                \"ECG_std\": segment[\"ECG\"].std(),\n",
    "                \"ECG_hr\": 60 / (segment[\"ECG\"].diff().abs().mean() + 1e-6),\n",
    "                \"BVP_mean\": segment[\"BVP\"].mean(),\n",
    "                \"BVP_std\": segment[\"BVP\"].std(),\n",
    "                \"GSR_mean\": segment[\"GSR\"].mean(),\n",
    "                \"GSR_std\": segment[\"GSR\"].std(),\n",
    "                \"GSR_slope\": np.polyfit(np.arange(len(segment)), segment[\"GSR\"], 1)[0],\n",
    "                \"Resp_mean\": segment[\"Resp\"].mean(),\n",
    "                \"Resp_std\": segment[\"Resp\"].std(),\n",
    "                \"Resp_rate\": len(np.where(np.diff(np.sign(segment[\"Resp\"] - segment[\"Resp\"].mean())))[0]) / 2,\n",
    "                \"Skin_temp_mean\": segment[\"Skin_Temp\"].mean(),\n",
    "                \"Skin_temp_std\": segment[\"Skin_Temp\"].std(),\n",
    "                \"EMG_mean\": segment[[\"EMG_z\", \"EMG_c\", \"EMG_t\"]].mean().mean(),\n",
    "                \"EMG_std\": segment[[\"EMG_z\", \"EMG_c\", \"EMG_t\"]].std().mean()\n",
    "            }\n",
    "            segments.append(features)\n",
    "    \n",
    "    return pd.DataFrame(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b1ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RuLSIF Algorithm for Change-Point Detection (unchanged)\n",
    "def compute_rulsif_change_scores(X, alpha=0.1, sigma=1.0, lambda_param=1e-3):\n",
    "    n = len(X) - 1\n",
    "    change_scores = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_t, X_t_next = X[i], X[i + 1]\n",
    "        \n",
    "        # Compute Gaussian Kernel Matrix\n",
    "        K_t = rbf_kernel(X_t.reshape(-1, 1), X_t.reshape(-1, 1), gamma=1/(2*sigma**2))\n",
    "        K_t_next = rbf_kernel(X_t_next.reshape(-1, 1), X_t_next.reshape(-1, 1), gamma=1/(2*sigma**2))\n",
    "        \n",
    "        # Compute Weights using Least Squares Importance Fitting (LSIF)\n",
    "        H = alpha * K_t + (1 - alpha) * K_t_next + lambda_param * np.eye(K_t.shape[0])\n",
    "        h = np.mean(K_t, axis=1)\n",
    "        \n",
    "        theta = np.linalg.solve(H, h)\n",
    "        \n",
    "        # Compute Change Score\n",
    "        change_scores[i] = np.mean(np.square(K_t_next.dot(theta) - 1))\n",
    "    \n",
    "    return change_scores\n",
    "\n",
    "# Identify significant changes and label opportune moments (unchanged)\n",
    "def label_opportune_moments(change_scores):\n",
    "    mean, std = np.mean(change_scores), np.std(change_scores)\n",
    "    threshold = mean + 3 * std\n",
    "    outliers = change_scores > threshold\n",
    "    \n",
    "    # Clustering the remaining scores\n",
    "    valid_indices = np.where(~outliers)[0]  # Indices of non-outliers\n",
    "    valid_scores = change_scores[valid_indices]\n",
    "    \n",
    "    if len(valid_scores) > 1:  # Ensure there are enough samples for clustering\n",
    "        kmeans = KMeans(n_clusters=2, random_state=42).fit(valid_scores.reshape(-1, 1))\n",
    "        centroids = kmeans.cluster_centers_.flatten()\n",
    "        high_cluster = np.argmax(centroids)\n",
    "        high_values = (kmeans.labels_ == high_cluster) & (valid_scores > centroids[high_cluster])\n",
    "        \n",
    "        # Map high_values back to the original indices\n",
    "        high_values_mapped = np.zeros_like(change_scores, dtype=bool)\n",
    "        high_values_mapped[valid_indices] = high_values\n",
    "    else:\n",
    "        high_values_mapped = np.zeros_like(change_scores, dtype=bool)\n",
    "    \n",
    "    # Mark opportune moments\n",
    "    opportune_moments = np.where(outliers | high_values_mapped)[0]\n",
    "    return opportune_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa5cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_encoder(input_shape):\n",
    "    from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, BatchNormalization\n",
    "\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    # Conv Block 1\n",
    "    x = Conv1D(32, kernel_size=4, activation='relu')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(32, kernel_size=4, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Conv Block 2\n",
    "    x = Conv1D(64, kernel_size=4, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(64, kernel_size=4, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Conv Block 3 (bottleneck)\n",
    "    x = Conv1D(32, kernel_size=4, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58bc70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_segments(physio_df, window_size=5):\n",
    "    samples_per_window = window_size * VALENCE_SAMPLING_RATE\n",
    "    segments = []\n",
    "\n",
    "    for i in range(0, len(physio_df) - samples_per_window + 1, samples_per_window):\n",
    "        segment = physio_df.iloc[i:i + samples_per_window]\n",
    "        segments.append(segment)\n",
    "\n",
    "    return segments  # Each segment is a DataFrame\n",
    "\n",
    "def build_fusion_model(input_length, num_modalities):\n",
    "    # One input per modality\n",
    "    inputs = [Input(shape=(input_length, 1)) for _ in range(num_modalities)]\n",
    "\n",
    "    # Shared CNN or separate CNNs per modality\n",
    "    cnn_encoders = [build_cnn_encoder((input_length, 1)) for _ in range(num_modalities)]\n",
    "    features = [cnn(inputs[i]) for i, cnn in enumerate(cnn_encoders)]\n",
    "\n",
    "    # Late fusion (feature-level)\n",
    "    merged = Concatenate()(features)\n",
    "    x = Dense(64, activation='relu')(merged)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_multimodal_input(segments, modalities):\n",
    "    inputs = {mod: [] for mod in modalities}\n",
    "    \n",
    "    for segment in segments:\n",
    "        for mod in modalities:\n",
    "            sig = segment[mod].values.reshape(-1, 1)  # (100, 1)\n",
    "            inputs[mod].append(sig)\n",
    "\n",
    "    # Convert to np arrays per modality\n",
    "    return [np.array(inputs[mod]) for mod in modalities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c266884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training User1 on: ['User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9680 1590], Test: [341 149]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      1.00      0.82       341\n",
      "         1.0       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.70       490\n",
      "   macro avg       0.35      0.50      0.41       490\n",
      "weighted avg       0.48      0.70      0.57       490\n",
      "\n",
      "AUC-ROC: 0.876\n",
      "\n",
      "Training User2 on: ['User1', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9591 1679], Test: [430  60]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       430\n",
      "         1.0       1.00      0.82      0.90        60\n",
      "\n",
      "    accuracy                           0.98       490\n",
      "   macro avg       0.99      0.91      0.94       490\n",
      "weighted avg       0.98      0.98      0.98       490\n",
      "\n",
      "AUC-ROC: 0.983\n",
      "\n",
      "Training User3 on: ['User1', 'User2', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9645 1625], Test: [376 114]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92       376\n",
      "         1.0       1.00      0.44      0.61       114\n",
      "\n",
      "    accuracy                           0.87       490\n",
      "   macro avg       0.93      0.72      0.77       490\n",
      "weighted avg       0.89      0.87      0.85       490\n",
      "\n",
      "AUC-ROC: 0.995\n",
      "\n",
      "Training User4 on: ['User5', 'User18', 'User26', 'User29']\n",
      "Train samples: 1960, Test samples: 490\n",
      "Class distribution - Train: [1684  276], Test: [433  57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.94       433\n",
      "         1.0       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.88       490\n",
      "   macro avg       0.44      0.50      0.47       490\n",
      "weighted avg       0.78      0.88      0.83       490\n",
      "\n",
      "AUC-ROC: 0.997\n",
      "\n",
      "Training User5 on: ['User4', 'User18', 'User26', 'User29']\n",
      "Train samples: 1960, Test samples: 490\n",
      "Class distribution - Train: [1697  263], Test: [420  70]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93       420\n",
      "         1.0       1.00      0.14      0.25        70\n",
      "\n",
      "    accuracy                           0.88       490\n",
      "   macro avg       0.94      0.57      0.59       490\n",
      "weighted avg       0.89      0.88      0.84       490\n",
      "\n",
      "AUC-ROC: 0.947\n",
      "\n",
      "Training User6 on: ['User1', 'User2', 'User3', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9592 1678], Test: [429  61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93       429\n",
      "         1.0       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.88       490\n",
      "   macro avg       0.44      0.50      0.47       490\n",
      "weighted avg       0.77      0.88      0.82       490\n",
      "\n",
      "AUC-ROC: 0.189\n",
      "\n",
      "Training User8 on: ['User1', 'User2', 'User3', 'User6', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9576 1694], Test: [445  45]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98       445\n",
      "         1.0       0.73      0.98      0.84        45\n",
      "\n",
      "    accuracy                           0.97       490\n",
      "   macro avg       0.87      0.97      0.91       490\n",
      "weighted avg       0.97      0.97      0.97       490\n",
      "\n",
      "AUC-ROC: 0.999\n",
      "\n",
      "Training User9 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9574 1696], Test: [447  43]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96       447\n",
      "         1.0       1.00      0.07      0.13        43\n",
      "\n",
      "    accuracy                           0.92       490\n",
      "   macro avg       0.96      0.53      0.54       490\n",
      "weighted avg       0.93      0.92      0.88       490\n",
      "\n",
      "AUC-ROC: 0.997\n",
      "\n",
      "Training User10 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9611 1659], Test: [410  80]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.92       410\n",
      "         1.0       0.58      1.00      0.73        80\n",
      "\n",
      "    accuracy                           0.88       490\n",
      "   macro avg       0.79      0.93      0.83       490\n",
      "weighted avg       0.93      0.88      0.89       490\n",
      "\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Training User11 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9604 1666], Test: [417  73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92       417\n",
      "         1.0       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.85       490\n",
      "   macro avg       0.43      0.50      0.46       490\n",
      "weighted avg       0.72      0.85      0.78       490\n",
      "\n",
      "AUC-ROC: 0.838\n",
      "\n",
      "Training User12 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9581 1689], Test: [440  50]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.88      0.94       440\n",
      "         1.0       0.49      1.00      0.65        50\n",
      "\n",
      "    accuracy                           0.89       490\n",
      "   macro avg       0.74      0.94      0.79       490\n",
      "weighted avg       0.95      0.89      0.91       490\n",
      "\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Training User13 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9578 1692], Test: [443  47]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       443\n",
      "         1.0       1.00      0.70      0.82        47\n",
      "\n",
      "    accuracy                           0.97       490\n",
      "   macro avg       0.98      0.85      0.90       490\n",
      "weighted avg       0.97      0.97      0.97       490\n",
      "\n",
      "AUC-ROC: 0.999\n",
      "\n",
      "Training User14 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9579 1691], Test: [442  48]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.71      0.83       442\n",
      "         1.0       0.27      1.00      0.43        48\n",
      "\n",
      "    accuracy                           0.74       490\n",
      "   macro avg       0.64      0.86      0.63       490\n",
      "weighted avg       0.93      0.74      0.79       490\n",
      "\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Training User15 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9599 1671], Test: [422  68]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.63      0.78       422\n",
      "         1.0       0.30      1.00      0.47        68\n",
      "\n",
      "    accuracy                           0.68       490\n",
      "   macro avg       0.65      0.82      0.62       490\n",
      "weighted avg       0.90      0.68      0.73       490\n",
      "\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Training User16 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9591 1679], Test: [430  60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93       430\n",
      "         1.0       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.88       490\n",
      "   macro avg       0.44      0.50      0.47       490\n",
      "weighted avg       0.77      0.88      0.82       490\n",
      "\n",
      "AUC-ROC: 0.994\n",
      "\n",
      "Training User17 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9594 1676], Test: [427  63]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95       427\n",
      "         1.0       0.62      1.00      0.76        63\n",
      "\n",
      "    accuracy                           0.92       490\n",
      "   macro avg       0.81      0.95      0.86       490\n",
      "weighted avg       0.95      0.92      0.93       490\n",
      "\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Training User18 on: ['User4', 'User5', 'User26', 'User29']\n",
      "Train samples: 1960, Test samples: 490\n",
      "Class distribution - Train: [1667  293], Test: [450  40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96       450\n",
      "         1.0       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.92       490\n",
      "   macro avg       0.46      0.50      0.48       490\n",
      "weighted avg       0.84      0.92      0.88       490\n",
      "\n",
      "AUC-ROC: 0.299\n",
      "\n",
      "Training User19 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9575 1695], Test: [446  44]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97       446\n",
      "         1.0       0.61      1.00      0.76        44\n",
      "\n",
      "    accuracy                           0.94       490\n",
      "   macro avg       0.81      0.97      0.86       490\n",
      "weighted avg       0.97      0.94      0.95       490\n",
      "\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Training User20 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9603 1667], Test: [418  72]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92       418\n",
      "         1.0       1.00      0.01      0.03        72\n",
      "\n",
      "    accuracy                           0.86       490\n",
      "   macro avg       0.93      0.51      0.47       490\n",
      "weighted avg       0.88      0.86      0.79       490\n",
      "\n",
      "AUC-ROC: 0.967\n",
      "\n",
      "Training User21 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9643 1627], Test: [378 112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      1.00      0.87       378\n",
      "         1.0       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.77       490\n",
      "   macro avg       0.39      0.50      0.44       490\n",
      "weighted avg       0.60      0.77      0.67       490\n",
      "\n",
      "AUC-ROC: 0.503\n",
      "\n",
      "Training User22 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User23', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9679 1591], Test: [342 148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      1.00      0.82       342\n",
      "         1.0       0.00      0.00      0.00       148\n",
      "\n",
      "    accuracy                           0.70       490\n",
      "   macro avg       0.35      0.50      0.41       490\n",
      "weighted avg       0.49      0.70      0.57       490\n",
      "\n",
      "AUC-ROC: 0.712\n",
      "\n",
      "Training User23 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User24', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9589 1681], Test: [432  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.94       432\n",
      "         1.0       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.88       490\n",
      "   macro avg       0.44      0.50      0.47       490\n",
      "weighted avg       0.78      0.88      0.83       490\n",
      "\n",
      "AUC-ROC: 0.791\n",
      "\n",
      "Training User24 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User25', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9610 1660], Test: [411  79]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91       411\n",
      "         1.0       0.00      0.00      0.00        79\n",
      "\n",
      "    accuracy                           0.84       490\n",
      "   macro avg       0.42      0.50      0.46       490\n",
      "weighted avg       0.70      0.84      0.77       490\n",
      "\n",
      "AUC-ROC: 0.806\n",
      "\n",
      "Training User25 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User27', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9573 1697], Test: [448  42]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.96       448\n",
      "         1.0       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.91       490\n",
      "   macro avg       0.46      0.50      0.48       490\n",
      "weighted avg       0.84      0.91      0.87       490\n",
      "\n",
      "AUC-ROC: 0.375\n",
      "\n",
      "Training User26 on: ['User4', 'User5', 'User18', 'User29']\n",
      "Train samples: 1960, Test samples: 490\n",
      "Class distribution - Train: [1697  263], Test: [420  70]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      1.00      0.94       420\n",
      "         1.0       1.00      0.27      0.43        70\n",
      "\n",
      "    accuracy                           0.90       490\n",
      "   macro avg       0.95      0.64      0.68       490\n",
      "weighted avg       0.91      0.90      0.87       490\n",
      "\n",
      "AUC-ROC: 0.990\n",
      "\n",
      "Training User27 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User28', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9587 1683], Test: [434  56]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.38      0.55       434\n",
      "         1.0       0.17      1.00      0.29        56\n",
      "\n",
      "    accuracy                           0.45       490\n",
      "   macro avg       0.59      0.69      0.42       490\n",
      "weighted avg       0.91      0.45      0.52       490\n",
      "\n",
      "AUC-ROC: 0.999\n",
      "\n",
      "Training User28 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User30']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9607 1663], Test: [414  76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.92       414\n",
      "         1.0       0.00      0.00      0.00        76\n",
      "\n",
      "    accuracy                           0.84       490\n",
      "   macro avg       0.42      0.50      0.46       490\n",
      "weighted avg       0.71      0.84      0.77       490\n",
      "\n",
      "AUC-ROC: 0.126\n",
      "\n",
      "Training User29 on: ['User4', 'User5', 'User18', 'User26']\n",
      "Train samples: 1960, Test samples: 490\n",
      "Class distribution - Train: [1723  237], Test: [394  96]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.61      0.76       394\n",
      "         1.0       0.38      1.00      0.55        96\n",
      "\n",
      "    accuracy                           0.68       490\n",
      "   macro avg       0.69      0.80      0.65       490\n",
      "weighted avg       0.88      0.68      0.72       490\n",
      "\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Training User30 on: ['User1', 'User2', 'User3', 'User6', 'User8', 'User9', 'User10', 'User11', 'User12', 'User13', 'User14', 'User15', 'User16', 'User17', 'User19', 'User20', 'User21', 'User22', 'User23', 'User24', 'User25', 'User27', 'User28']\n",
      "Train samples: 11270, Test samples: 490\n",
      "Class distribution - Train: [9622 1648], Test: [399  91]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      1.00      0.90       399\n",
      "         1.0       0.00      0.00      0.00        91\n",
      "\n",
      "    accuracy                           0.81       490\n",
      "   macro avg       0.41      0.50      0.45       490\n",
      "weighted avg       0.66      0.81      0.73       490\n",
      "\n",
      "AUC-ROC: 0.908\n",
      "\n",
      "Results saved to cnn_fusion_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Harshit Kumar\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    user_reports = []\n",
    "\n",
    "    # User profiles with pre-defined clusters\n",
    "    df_profiles = pd.DataFrame({\n",
    "        \"User\": [\"User1\", \"User2\", \"User3\", \"User4\", \"User5\", \"User6\", \"User8\", \"User9\", \"User10\",\n",
    "                \"User11\", \"User12\", \"User13\", \"User14\", \"User15\", \"User16\", \"User17\", \"User18\",\n",
    "                \"User19\", \"User20\", \"User21\", \"User22\", \"User23\", \"User24\", \"User25\", \"User26\",\n",
    "                \"User27\", \"User28\", \"User29\", \"User30\"],\n",
    "        \"Cluster\": [0, 0, 0, 1, 1, 0, 0, 0, 0, \n",
    "                   0, 0, 0, 0, 0, 0, 0, 1,\n",
    "                   0, 0, 0, 0, 0, 0, 0, 1,\n",
    "                   0, 0, 1, 0]\n",
    "    })\n",
    "\n",
    "    # Preprocess data for all users\n",
    "    user_inputs = {}\n",
    "    user_labels = {}\n",
    "    for i in range(1, 31):\n",
    "        user_id = f\"User{i}\"\n",
    "        if i == 7:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            physio_file = f\"../case_dataset-master/case_dataset-master/data/raw/physiological/sub{i}_DAQ.txt\"\n",
    "            \n",
    "            # Load physiological data\n",
    "            df_physio = load_data(physio_file)\n",
    "\n",
    "            # Segment raw data\n",
    "            raw_segments = get_raw_segments(df_physio)  # shape: list of DataFrames\n",
    "\n",
    "            # Prepare modality-specific raw inputs (e.g., ecg, bvp, gsr)\n",
    "            #X_modalities = prepare_multimodal_input(raw_segments, modalities=[\"ECG\", \"BVP\", \"GSR\"])\n",
    "            X_modalities = prepare_multimodal_input(raw_segments, modalities=[\"BVP\", \"GSR\", \"ECG\", \"Resp\", \"EMG_c\"])\n",
    "            \n",
    "\n",
    "            # Create segmented data for feature extraction (mean features)\n",
    "            segmented_data = segment_data(df_physio)\n",
    "\n",
    "            # Compute RuLSIF change scores on physiological mean features\n",
    "            physio_features = segmented_data[['ECG_mean', 'BVP_mean', 'GSR_mean', \n",
    "                                           'Resp_mean', 'Skin_temp_mean', 'EMG_mean']].values\n",
    "            # physio_features = segmented_data[['ECG_mean', 'BVP_mean', 'GSR_mean']].values\n",
    "            change_scores = compute_rulsif_change_scores(physio_features)\n",
    "\n",
    "            # Label opportune moments\n",
    "            opportune_moments = label_opportune_moments(change_scores)\n",
    "            labels = np.zeros(len(raw_segments))\n",
    "            labels[opportune_moments] = 1\n",
    "\n",
    "            # Filter out segments with any NaNs across modalities\n",
    "            valid_mask = ~np.any([np.isnan(X).any(axis=(1, 2)) for X in X_modalities], axis=0)\n",
    "            X_modalities = [X[valid_mask] for X in X_modalities]\n",
    "            labels = labels[valid_mask]\n",
    "\n",
    "            user_inputs[user_id] = X_modalities  # list of modality arrays\n",
    "            user_labels[user_id] = labels\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Data for {user_id} not found. Skipping...\")\n",
    "            continue\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for user, X_modalities in user_inputs.items():\n",
    "        # Get user's cluster\n",
    "        cluster = df_profiles[df_profiles[\"User\"] == user][\"Cluster\"].values[0]\n",
    "        similar_users = [u for u in df_profiles[df_profiles[\"Cluster\"] == cluster][\"User\"] if u != user]\n",
    "\n",
    "        # Aggregate training data from users in the same cluster\n",
    "        train_modalities = [[] for _ in range(len(X_modalities))]  # One list per modality\n",
    "        train_labels = []\n",
    "\n",
    "        for u in similar_users:\n",
    "            if u in user_inputs:\n",
    "                for i, modality_data in enumerate(user_inputs[u]):\n",
    "                    train_modalities[i].append(modality_data)\n",
    "                train_labels.append(user_labels[u])\n",
    "\n",
    "        # Skip if no training data\n",
    "        if not train_labels:\n",
    "            print(f\"No training data available for {user}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Stack per-modality arrays\n",
    "        train_modalities = [np.vstack(mod_data) for mod_data in train_modalities]\n",
    "        train_labels = np.hstack(train_labels)\n",
    "\n",
    "        # Prepare test data\n",
    "        test_modalities = [np.array(modality) for modality in X_modalities]\n",
    "        test_labels = user_labels[user]\n",
    "\n",
    "        print(f\"\\nTraining {user} on: {[u for u in similar_users if u in user_inputs]}\")\n",
    "        print(f\"Train samples: {len(train_labels)}, Test samples: {len(test_labels)}\")\n",
    "        print(f\"Class distribution - Train: {np.bincount(train_labels.astype(int))}, Test: {np.bincount(test_labels.astype(int))}\")\n",
    "\n",
    "        # Build and compile CNN fusion model\n",
    "        model = build_fusion_model(input_length=100, num_modalities=len(X_modalities))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                    loss=\"binary_crossentropy\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "        # Compute class weights for imbalance\n",
    "        class_weights = compute_class_weight(class_weight=\"balanced\", \n",
    "                                            classes=np.unique(train_labels), \n",
    "                                            y=train_labels)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        # Train the model\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        train_modalities_train = []\n",
    "        train_modalities_val = []\n",
    "\n",
    "        for mod_data in train_modalities:\n",
    "            X_tr, X_val = train_test_split(mod_data, test_size=0.2, random_state=42, stratify=train_labels)\n",
    "            train_modalities_train.append(X_tr)\n",
    "            train_modalities_val.append(X_val)\n",
    "\n",
    "        y_train, y_val = train_test_split(train_labels, test_size=0.2, random_state=42, stratify=train_labels)\n",
    "\n",
    "        model.fit(\n",
    "                train_modalities_train, y_train,\n",
    "                validation_data=(train_modalities_val, y_val),\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                class_weight=class_weights,\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "        # Evaluate on test data\n",
    "\n",
    "        # y_pred = model.predict(test_modalities)\n",
    "        # y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "       # Tune threshold on validation set (not test!)\n",
    "        y_val_probs = model.predict(train_modalities_val).flatten()\n",
    "\n",
    "        thresholds = np.arange(0.05, 0.95, 0.01)\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "\n",
    "        for t in thresholds:\n",
    "            preds = (y_val_probs > t).astype(int)\n",
    "            f1 = f1_score(y_val, preds, average='macro', zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = t\n",
    "\n",
    "        # Now use that threshold on the test set\n",
    "        y_pred_probs = model.predict(test_modalities).flatten()\n",
    "        y_pred_classes = (y_pred_probs > best_threshold).astype(int)\n",
    "\n",
    "        # Create a directory for saved models\n",
    "        os.makedirs(\"saved_models_cnn_fusion\", exist_ok=True)\n",
    "\n",
    "        # Create a subfolder for this user\n",
    "        user_dir = os.path.join(\"saved_models_cnn_fusion\", f\"user_{user}\")\n",
    "        os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "        # Save the model\n",
    "        model.save(os.path.join(user_dir, \"model.h5\"))\n",
    "\n",
    "        # Also save the best threshold\n",
    "        with open(os.path.join(user_dir, \"threshold.txt\"), \"w\") as f:\n",
    "            f.write(str(round(best_threshold, 4)))\n",
    "\n",
    "\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(test_labels, y_pred_classes).ravel()\n",
    "        \n",
    "        TPR = recall_score(test_labels, y_pred_classes)               # Sensitivity / Recall\n",
    "        TNR = tn / (tn + fp) if (tn + fp) > 0 else 0.0               # Specificity\n",
    "        FPR = fp / (fp + tn) if (fp + tn) > 0 else 0.0               # False positive rate\n",
    "        F1 = f1_score(test_labels, y_pred_classes, average='weighted')\n",
    "        AUC = roc_auc_score(test_labels, y_pred_probs)\n",
    "        ACC = accuracy_score(test_labels, y_pred_classes)\n",
    "\n",
    "        results.append([\n",
    "                        user,\n",
    "                        round(TPR, 4),\n",
    "                        round(TNR, 4),\n",
    "                        round(FPR, 4),\n",
    "                        round(F1, 4),\n",
    "                        round(AUC, 4),\n",
    "                        round(ACC, 4),\n",
    "                        round(best_threshold, 4)\n",
    "                    ])\n",
    "\n",
    "        print(classification_report(test_labels, y_pred_classes))\n",
    "        print(f\"AUC-ROC: {roc_auc_score(test_labels, y_pred_probs):.3f}\")\n",
    "        \n",
    "    # Save results to CSV\n",
    "    output_file = \"cnn_fusion_results.csv\"\n",
    "    with open(output_file, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"User\", \"TPR\", \"TNR\", \"FPR\", \"Weighted F1\", \"AUC\", \"Accuracy\", \"Threshold\"])\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426a759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YO",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
